{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EAR/MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to 2_3_data_analysis.csv\n",
      "Data written to 3_2_data_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import csv\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "# Initialize dlib's face detector and landmark predictor\n",
    "predictor_path = r\"F:\\SKRIPSI\\TA\\Kartivel\\Driver-Drowsiness-Detection-main\\shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = dist.euclidean(mouth[14], mouth[18])  # 65, 59\n",
    "    B = dist.euclidean(mouth[12], mouth[16])  # 63, 57\n",
    "    C = dist.euclidean(mouth[0], mouth[6])    # 49, 55\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def process_videos_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith((\".mp4\",\".mov\",\".MOV\")):\n",
    "            video_path = os.path.join(folder_path, filename)\n",
    "            process_video(video_path)\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_title = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    csv_filename = f\"{video_title}_data_analysis.csv\"\n",
    "    data_list = []\n",
    "\n",
    "    # Get the video's frames per second (fps)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    delay = int(100 / fps)  # Calculate delay in milliseconds\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray, 0)\n",
    "\n",
    "        if faces:\n",
    "            for face in faces:\n",
    "                shape = predictor(gray, face)\n",
    "                landmarks = face_utils.shape_to_np(shape)\n",
    "                ear = 0\n",
    "                mar = 0\n",
    "\n",
    "                if len(landmarks) >= 68:\n",
    "                    leftEye = landmarks[36:42]\n",
    "                    rightEye = landmarks[42:48]\n",
    "                    mouth = landmarks[48:68]\n",
    "\n",
    "                    ear = (eye_aspect_ratio(leftEye) + eye_aspect_ratio(rightEye)) / 2.0\n",
    "                    mar = mouth_aspect_ratio(mouth)\n",
    "\n",
    "                    cv2.drawContours(frame, [cv2.convexHull(leftEye)], -1, (0, 255, 0), 1)\n",
    "                    cv2.drawContours(frame, [cv2.convexHull(rightEye)], -1, (0, 255, 0), 1)\n",
    "                    cv2.drawContours(frame, [cv2.convexHull(mouth)], -1, (0, 255, 0), 1)\n",
    "\n",
    "                    cv2.putText(frame, f\"EAR: {ear:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f\"MAR: {mar:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "                frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "                data_list.append([frame_number, ear, mar])\n",
    "\n",
    "        else:\n",
    "            # No faces detected\n",
    "            frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            data_list.append([frame_number, 0, 0])\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Frame', 'EAR', 'MAR'])\n",
    "        csvwriter.writerows(data_list)\n",
    "        print(f\"Data written to {csv_filename}\")\n",
    "\n",
    "video_folder_path = r\"F:\\SKRIPSI\\TA\\UTA-RLDD Dataset\\3\\3Video\\New_folder\"\n",
    "process_videos_in_folder(video_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to 1-1_data_analysis.csv\n",
      "Data written to 1-2_data_analysis.csv\n",
      "Data written to 1-3_data_analysis.csv\n",
      "Data written to 10-1_data_analysis.csv\n",
      "Data written to 10-3_data_analysis.csv\n",
      "Data written to 11-1_data_analysis.csv\n",
      "Data written to 11-2_data_analysis.csv\n",
      "Data written to 11-3_data_analysis.csv\n",
      "Data written to 12-1_data_analysis.csv\n",
      "Data written to 13-1_data_analysis.csv\n",
      "Data written to 13-2_data_analysis.csv\n",
      "Data written to 14-1_data_analysis.csv\n",
      "Data written to 14-2_data_analysis.csv\n",
      "Data written to 14-3_data_analysis.csv\n",
      "Data written to 2-1_data_analysis.csv\n",
      "Data written to 2-2_data_analysis.csv\n",
      "Data written to 2-3_data_analysis.csv\n",
      "Data written to 3-1_data_analysis.csv\n",
      "Data written to 3-2_data_analysis.csv\n",
      "Data written to 3-3_data_analysis.csv\n",
      "Data written to 4-1_data_analysis.csv\n",
      "Data written to 4-2_data_analysis.csv\n",
      "Data written to 4-3_data_analysis.csv\n",
      "Data written to 5-1_data_analysis.csv\n",
      "Data written to 5-2_data_analysis.csv\n",
      "Data written to 5-3_data_analysis.csv\n",
      "Data written to 6-1_data_analysis.csv\n",
      "Data written to 6-2_data_analysis.csv\n",
      "Data written to 6-3_data_analysis.csv\n",
      "Data written to 7-2_data_analysis.csv\n",
      "Data written to 7-3_data_analysis.csv\n",
      "Data written to 8-1_data_analysis.csv\n",
      "Data written to 8-2_data_analysis.csv\n",
      "Data written to 8-3_data_analysis.csv\n",
      "Data written to 9-2_data_analysis.csv\n",
      "Data written to 9-3_data_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import csv\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "#inisialisasi prediktor dlib\n",
    "predictor_path = r\"F:\\SKRIPSI\\TA\\Kartivel\\Driver-Drowsiness-Detection-main\\shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = dist.euclidean(mouth[14], mouth[18])  # 65, 59\n",
    "    B = dist.euclidean(mouth[12], mouth[16])  # 63, 57\n",
    "    C = dist.euclidean(mouth[0], mouth[6])   # 49, 55\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def calculate_eye_openness(eye_image):\n",
    "    \"\"\" Calculate the openness of the eye from the binary image \"\"\"\n",
    "    white_pixels = np.sum(eye_image == 255)\n",
    "    total_pixels = eye_image.size\n",
    "    return white_pixels / total_pixels if total_pixels > 0 else 0\n",
    "\n",
    "def get_eye_image(frame, eye_points):\n",
    "    \"\"\" Extract and return a binary image of the eye \"\"\"\n",
    "    mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [eye_points], 255)\n",
    "    eye = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    (x, y, w, h) = cv2.boundingRect(eye_points)\n",
    "    eye = eye[y:y+h, x:x+w]\n",
    "    gray_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_eye = cv2.threshold(gray_eye, 30, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_eye\n",
    "\n",
    "def process_videos_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(folder_path, filename)\n",
    "            process_video(video_path)\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_title = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    csv_filename = f\"{video_title}_data_analysis.csv\"\n",
    "    data_list = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray, 0)\n",
    "\n",
    "        if faces:\n",
    "            for face in faces:\n",
    "                shape = predictor(gray, face)\n",
    "                landmarks = face_utils.shape_to_np(shape)\n",
    "                #ear = 0\n",
    "                mar =0\n",
    "\n",
    "                if len(landmarks) >= 48:\n",
    "                    leftEye = landmarks[36:42]\n",
    "                    rightEye = landmarks[42:48]\n",
    "                    mouth = landmarks[48:68]\n",
    "                    left_eye_image = get_eye_image(frame, leftEye)\n",
    "                    right_eye_image = get_eye_image(frame, rightEye)\n",
    "\n",
    "                    left_eye_openness = calculate_eye_openness(left_eye_image)\n",
    "                    right_eye_openness = calculate_eye_openness(right_eye_image)\n",
    "                    eye_openness = ((left_eye_openness + right_eye_openness) / 2 ) - 0.2\n",
    "                    mar = mouth_aspect_ratio(mouth)\n",
    "                    #ear = eye_aspect_ratio()\n",
    "\n",
    "                    cv2.drawContours(frame, [cv2.convexHull(leftEye)], -1, (0, 255, 0), 1)\n",
    "                    cv2.drawContours(frame, [cv2.convexHull(rightEye)], -1, (0, 255, 0), 1)\n",
    "                    cv2.drawContours(frame, [cv2.convexHull(mouth)], -1, (0, 255, 0), 1)\n",
    "\n",
    "                    cv2.imshow(\"Left Eye Binary\", left_eye_image)\n",
    "                    cv2.imshow(\"Right Eye Binary\", right_eye_image)\n",
    "                    cv2.putText(frame, f\"Openness: {eye_openness:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    #cv2.putText(frame, f\"Openness: {ear:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f\"MAR: {mar:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    eye_openness =((left_eye_openness + right_eye_openness) / 2) - 0.2\n",
    "                    #ear = 0\n",
    "                    mar = 0\n",
    "\n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "                frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "                video_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0 \n",
    "                data_list.append([frame_number, video_time, eye_openness, mar])\n",
    "\n",
    "        else:\n",
    "            # No faces detected\n",
    "            frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            video_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0 \n",
    "            data_list.append([frame_number, video_time, 0, 0]) \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Frame', 'time', 'Openness', 'MAR'])\n",
    "        csvwriter.writerows(data_list)\n",
    "        print(f\"Data written to {csv_filename}\")\n",
    "\n",
    "\n",
    "video_folder_path = r\"F:\\SKRIPSI\\TA\\DROZY\\videos_i8\\real\"\n",
    "process_videos_in_folder(video_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPOLASI 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation complete for all CSV files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set your directory path where CSV files are stored\n",
    "directory_path = r'F:\\SKRIPSI\\TA\\Fix_code\\SkripSHYs\\FixedDataset\\NonAugmented\\test'  # Replace with your directory path\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check for CSV files\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Replace 0.0 with NaN for interpolation in 'Openness' and 'MAR' columns\n",
    "        df['EAR'] = df['EAR'].replace(0.0, np.nan)\n",
    "        df['MAR'] = df['MAR'].replace(0.0, np.nan)\n",
    "        \n",
    "        # Use linear interpolation to fill NaNs in both columns\n",
    "        df['EAR'].interpolate(method='linear', inplace=True)\n",
    "        df['MAR'].interpolate(method='linear', inplace=True)\n",
    "        \n",
    "        # After interpolation, if you need to round the values or process them in some way, do it here\n",
    "        \n",
    "        # Save the updated DataFrame back to its CSV file\n",
    "        df.to_csv(file_path, index=False)  # Save the file with interpolated data\n",
    "\n",
    "print(\"Interpolation complete for all CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolasi per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation complete for the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the input file path and output file path\n",
    "input_file_path = r'F:\\SKRIPSI\\TA\\Fix_code\\SkripSHYs\\PERCLOS\\1_2_data_analysis.csv'  # Replace with your input file path\n",
    "output_file_path = r'F:\\SKRIPSI\\TA\\Fix_code\\SkripSHYs\\PERCLOS\\1-2_final_output.csv'  # Replace with your output file path\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Replace 0.0 with NaN for interpolation in 'EAR' and 'MAR' columns\n",
    "df['EAR'] = df['EAR'].replace(0.0, np.nan)\n",
    "df['MAR'] = df['MAR'].replace(0.0, np.nan)\n",
    "\n",
    "# Use linear interpolation to fill NaNs in both columns\n",
    "df['EAR'].interpolate(method='linear', inplace=True)\n",
    "df['MAR'].interpolate(method='linear', inplace=True)\n",
    "\n",
    "# After interpolation, if you need to round the values or process them in some way, do it here\n",
    "\n",
    "# Save the updated DataFrame to the output CSV file\n",
    "df.to_csv(output_file_path, index=False)  # Save the file with interpolated data\n",
    "\n",
    "print(\"Interpolation complete for the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 18263\n",
      "A (1/20 of total frames): 913\n",
      "O (Open eyes state mean): 0.3443858373539099\n",
      "C (Closed eyes state mean): 0.22481621155795736\n",
      "Threshold: 0.24873013671714786\n",
      "8415     0.260008\n",
      "14636    0.259980\n",
      "9963     0.259946\n",
      "8269     0.259887\n",
      "8416     0.259857\n",
      "           ...   \n",
      "15695    0.107453\n",
      "15683    0.106405\n",
      "14666    0.106226\n",
      "6988     0.105514\n",
      "15682    0.090235\n",
      "Name: EAR, Length: 913, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_filepath = r'F:\\SKRIPSI\\TA\\Fix_code\\SkripSHYs\\FixedDataset\\NonAugmented\\test\\1_2_data_analysis.csv'\n",
    "\n",
    "def calculate_threshold(csv_filepath):\n",
    "    data = pd.read_csv(csv_filepath)\n",
    "\n",
    "    # Hitung nilai 1/20 total data\n",
    "    total_frames = len(data)\n",
    "    A = total_frames // 20\n",
    "    A = max(A, 1)\n",
    "\n",
    "    sorted_data = data.sort_values(by='EAR', ascending=False)\n",
    "\n",
    "    # hitung O and C untuk treshold\n",
    "    O = sorted_data['EAR'].head(A).mean()\n",
    "    C = sorted_data['EAR'].tail(A).mean()\n",
    "\n",
    "    # Hitung Treshold\n",
    "    threshold = (O - C) * 0.2 + C\n",
    "\n",
    "    print(\"Total frames:\", total_frames)\n",
    "    print(\"A (1/20 of total frames):\", A)\n",
    "    print(\"O (Open eyes state mean):\", O)\n",
    "    print(\"C (Closed eyes state mean):\", C)\n",
    "    print(\"Threshold:\", threshold)\n",
    "    print (sorted_data['EAR'].tail(A))\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "threshold = calculate_threshold(csv_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COBA COBA PERCLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24873013671714786\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fungsi untuk memproses data per 30 baris dan mengelompokkan berdasarkan threshold\n",
    "def process_data(file_path, threshold):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'EAR' not in df.columns or 'MAR' not in df.columns:\n",
    "        raise ValueError(\"Kolom 'EAR' atau 'MAR' tidak ditemukan dalam file CSV\")\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    # Pilah data per 30 baris\n",
    "    for i in range(0, len(df), 30):\n",
    "        chunk_openness = df['EAR'].iloc[i:i+30]\n",
    "        chunk_mar = df['MAR'].iloc[i:i+30]\n",
    "\n",
    "        # Pisahkan data di atas dan di bawah threshold\n",
    "        above_threshold = chunk_openness[chunk_openness > threshold]\n",
    "        below_threshold = chunk_openness[chunk_openness <= threshold]\n",
    "        \n",
    "        # Hitung jumlah masing-masing kelompok\n",
    "        sum_above = above_threshold.sum()\n",
    "        sum_below = below_threshold.sum()\n",
    "\n",
    "        # Hitung standar deviasi MAR untuk setiap chunk\n",
    "        std_mar = chunk_mar.std()\n",
    "        \n",
    "        result.append({\n",
    "            'Sum_Above_Threshold': sum_above,\n",
    "            'Sum_Below_Threshold': sum_below,\n",
    "            'MAR_Std': std_mar\n",
    "        })\n",
    "\n",
    "    # Buat DataFrame dari hasil\n",
    "    result_df = pd.DataFrame(result)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Fungsi untuk melakukan perhitungan rasio dan hanya memasukkan nilai di atas 0\n",
    "def calculate_ratio(data):\n",
    "    data['PERCLOS'] = data['Sum_Below_Threshold'] / (data['Sum_Above_Threshold'] + data['Sum_Below_Threshold'])\n",
    "    \n",
    "    # Hanya simpan baris dengan nilai PERCLOS di atas 0\n",
    "    result_df = data[(data['PERCLOS'] > 0) & (data['PERCLOS'] < 0.8)]\n",
    "    result_df = result_df[['PERCLOS', 'MAR_Std']]\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "file_path = r'F:\\SKRIPSI\\TA\\Fix_code\\SkripSHYs\\FixedDataset\\NonAugmented\\test\\1_2_data_analysis.csv' \n",
    "Threshold = threshold  # Ganti dengan nilai threshold yang diinginkan\n",
    "final_output_path = r'F:\\SKRIPSI\\TA\\Fix_code\\SkripSHYs\\FixedDataset\\NonAugmented\\test\\1_2_ready_output.csv'\n",
    "\n",
    "processed_data = process_data(file_path, Threshold)\n",
    "final_result = calculate_ratio(processed_data)\n",
    "final_result.to_csv(final_output_path, index=False)\n",
    "print(threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
